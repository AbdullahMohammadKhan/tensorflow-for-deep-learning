{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(456)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "data = iris['data']\n",
    "out = iris['target']\n",
    "train_x, test_x, train_y, test_y = train_test_split(data, out, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted train Classification Accuracy: 1.000000\n",
      "Weighted test Classification Accuracy: 0.980000\n"
     ]
    }
   ],
   "source": [
    "sklearn_model = RandomForestClassifier(class_weight=\"balanced\", n_estimators=20)\n",
    "sklearn_model.fit(train_x, train_y)\n",
    "\n",
    "train_y_pred = sklearn_model.predict(train_x)\n",
    "test_y_pred = sklearn_model.predict(test_x)\n",
    "\n",
    "weighted_score = accuracy_score(train_y, train_y_pred)\n",
    "print(\"Weighted train Classification Accuracy: %f\" % weighted_score)\n",
    "weighted_score = accuracy_score(test_y, test_y_pred)\n",
    "print(\"Weighted test Classification Accuracy: %f\" % weighted_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def eval_tox21_hyperparams(n_hidden=50, n_layers=1, learning_rate=.001,\n",
    "                           dropout_prob=0.5, n_epochs=45, batch_size=100,\n",
    "                           weight_positives=True):\n",
    "\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(\"Model hyperparameters\")\n",
    "    print(\"n_hidden = %d\" % n_hidden)\n",
    "    print(\"n_layers = %d\" % n_layers)\n",
    "    print(\"learning_rate = %f\" % learning_rate)\n",
    "    print(\"n_epochs = %d\" % n_epochs)\n",
    "    print(\"batch_size = %d\" % batch_size)\n",
    "    print(\"weight_positives = %s\" % str(weight_positives))\n",
    "    print(\"dropout_prob = %f\" % dropout_prob)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    d = 4\n",
    "    x = tf.placeholder(tf.float32, (None, d))\n",
    "    y = tf.placeholder(tf.float32, (None))\n",
    "\n",
    "    w = tf.Variable(tf.random_normal((d, n_hidden)))\n",
    "    b = tf.Variable(tf.random_normal((n_hidden,)))\n",
    "    x_hidden = tf.nn.relu(tf.matmul(x, w) + b)\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    x_hidden = tf.nn.dropout(x_hidden, keep_prob)\n",
    "\n",
    "    w_out = tf.Variable(tf.random_normal((n_hidden, 1)))\n",
    "    b_out = tf.Variable(tf.random_normal((1,)))\n",
    "    y_logit = tf.matmul(x_hidden, w_out) + b_out\n",
    "    y_pred = tf.round(tf.sigmoid(y_logit))\n",
    "\n",
    "    y_expand = tf.expand_dims(y, 1)\n",
    "    entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=y_logit, labels=y_expand)\n",
    "    l = tf.reduce_sum(entropy)\n",
    "\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(l)\n",
    "    \n",
    "    N = train_x.shape[0]\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        step = 0\n",
    "        for epoch in range(n_epochs):\n",
    "            pos = 0\n",
    "            while pos < N:\n",
    "                feed_dict = {x: train_x[pos:pos+batch_size], y: train_y[pos:pos+batch_size], keep_prob: dropout_prob}\n",
    "                _, loss = sess.run([train_op, l], feed_dict=feed_dict)\n",
    "                step += 1\n",
    "                pos += batch_size\n",
    "        y_pred_out = sess.run(y_pred, feed_dict={x: test_x, keep_prob: 1.0})\n",
    "        print(\"Accuracy Score: {}\".format(accuracy_score(test_y, y_pred_out)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 50\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 10\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "Accuracy Score: 0.74\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 50\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 10\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "Accuracy Score: 0.32\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 50\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 10\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 1.000000\n",
      "---------------------------------------------\n",
      "Accuracy Score: 0.42\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 50\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 10\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 1.000000\n",
      "---------------------------------------------\n",
      "Accuracy Score: 0.42\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 50\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 10\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "Accuracy Score: 0.42\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 50\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 10\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "Accuracy Score: 0.32\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 50\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 10\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 1.000000\n",
      "---------------------------------------------\n",
      "Accuracy Score: 0.32\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 50\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 10\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 1.000000\n",
      "---------------------------------------------\n",
      "Accuracy Score: 0.42\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 50\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 10\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "Accuracy Score: 0.42\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 50\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 10\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "Accuracy Score: 0.42\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 50\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 10\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 1.000000\n",
      "---------------------------------------------\n",
      "Accuracy Score: 0.32\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 50\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 10\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 1.000000\n",
      "---------------------------------------------\n",
      "Accuracy Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "n_reps = 3\n",
    "hidden_sizes = [50]\n",
    "epochs = [10]\n",
    "dropouts = [.5, 1.0]\n",
    "num_layers = [1, 2]\n",
    "\n",
    "for rep in range(n_reps):\n",
    "    for n_epochs in epochs:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            for dropout in dropouts:\n",
    "                for n_layers in num_layers:\n",
    "                    eval_tox21_hyperparams(n_hidden=hidden_size, n_epochs=n_epochs, dropout_prob=dropout, n_layers=n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
